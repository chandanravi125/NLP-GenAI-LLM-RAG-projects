{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This projects is on going"
      ],
      "metadata": {
        "id": "Cy1P1ciP0rR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Intentions of a Chatbot\n",
        "Now we need to define a few simple intents and a group of messages that match those intents and also map some responses based on each intent category. I’ll create a JSON file named “intents.json” including this data as follows:"
      ],
      "metadata": {
        "id": "J3nYjFG2t5lF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Chatbot with Python and Machine Learning\n",
        "To create a chatbot with Python and Machine Learning, you need to install some packages. All the packages you need to install to create a chatbot with Machine Learning using the Python programming language are mentioned below:\n",
        "* tensorflow==2.3.1\n",
        "* nltk==3.5\n",
        "* colorama==0.4.3\n",
        "* numpy==1.18.5\n",
        "* scikit_learn==0.23.2\n",
        "* Flask==1.1.2"
      ],
      "metadata": {
        "id": "9q9g6mKjt2xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\"intents\": [\n",
        "    {\"tag\": \"greeting\",\n",
        "     \"patterns\": [\"Hi\", \"Hey\", \"Is anyone there?\", \"Hello\", \"Hay\"],\n",
        "     \"responses\": [\"Hello\", \"Hi\", \"Hi there\"]\n",
        "    },\n",
        "     {\"tag\": \"goodbye\",\n",
        "     \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\n",
        "     \"responses\": [\"See you later\", \"Have a nice day\", \"Bye! Come back again\"]\n",
        "    },\n",
        "    {\"tag\": \"thanks\",\n",
        "     \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\", \"Thanks for the help\"],\n",
        "     \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\", \"You're most welcome!\"]\n",
        "    },\n",
        "    {\"tag\": \"about\",\n",
        "     \"patterns\": [\"Who are you?\", \"What are you?\", \"Who you are?\" ],\n",
        "     \"responses\": [\"I.m Joana, your bot assistant\", \"I'm Joana, an Artificial Intelligent bot\"]\n",
        "    },\n",
        "    {\"tag\": \"name\",\n",
        "    \"patterns\": [\"what is your name\", \"what should I call you\", \"whats your name?\"],\n",
        "    \"responses\": [\"You can call me Joana.\", \"I'm Joana!\", \"Just call me as Joana\"]\n",
        "    },\n",
        "    {\"tag\": \"help\",\n",
        "    \"patterns\": [\"Could you help me?\", \"give me a hand please\", \"Can you help?\", \"What can you do for me?\", \"I need a support\", \"I need a help\", \"support me please\"],\n",
        "    \"responses\": [\"Tell me how can assist you\", \"Tell me your problem to assist you\", \"Yes Sure, How can I support you\"]\n",
        "    },\n",
        "    {\"tag\": \"createaccount\",\n",
        "    \"patterns\": [\"I need to create a new account\", \"how to open a new account\", \"I want to create an account\", \"can you create an account for me\", \"how to open a new account\"],\n",
        "    \"responses\": [\"You can just easily create a new account from our web site\", \"Just go to our web site and follow the guidelines to create a new account\"]\n",
        "    },\n",
        "    {\"tag\": \"complaint\",\n",
        "    \"patterns\": [\"have a complaint\", \"I want to raise a complaint\", \"there is a complaint about a service\"],\n",
        "    \"responses\": [\"Please provide us your complaint in order to assist you\", \"Please mention your complaint, we will reach you and sorry for any inconvenience caused\"]\n",
        "    }\n",
        "]\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIyP2jhnuTZl",
        "outputId": "8e9a492a-1aa9-4a0d-f02d-ae6c916e9977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'tag': 'greeting',\n",
              "   'patterns': ['Hi', 'Hey', 'Is anyone there?', 'Hello', 'Hay'],\n",
              "   'responses': ['Hello', 'Hi', 'Hi there']},\n",
              "  {'tag': 'goodbye',\n",
              "   'patterns': ['Bye', 'See you later', 'Goodbye'],\n",
              "   'responses': ['See you later', 'Have a nice day', 'Bye! Come back again']},\n",
              "  {'tag': 'thanks',\n",
              "   'patterns': ['Thanks',\n",
              "    'Thank you',\n",
              "    \"That's helpful\",\n",
              "    'Thanks for the help'],\n",
              "   'responses': ['Happy to help!',\n",
              "    'Any time!',\n",
              "    'My pleasure',\n",
              "    \"You're most welcome!\"]},\n",
              "  {'tag': 'about',\n",
              "   'patterns': ['Who are you?', 'What are you?', 'Who you are?'],\n",
              "   'responses': ['I.m Joana, your bot assistant',\n",
              "    \"I'm Joana, an Artificial Intelligent bot\"]},\n",
              "  {'tag': 'name',\n",
              "   'patterns': ['what is your name',\n",
              "    'what should I call you',\n",
              "    'whats your name?'],\n",
              "   'responses': ['You can call me Joana.',\n",
              "    \"I'm Joana!\",\n",
              "    'Just call me as Joana']},\n",
              "  {'tag': 'help',\n",
              "   'patterns': ['Could you help me?',\n",
              "    'give me a hand please',\n",
              "    'Can you help?',\n",
              "    'What can you do for me?',\n",
              "    'I need a support',\n",
              "    'I need a help',\n",
              "    'support me please'],\n",
              "   'responses': ['Tell me how can assist you',\n",
              "    'Tell me your problem to assist you',\n",
              "    'Yes Sure, How can I support you']},\n",
              "  {'tag': 'createaccount',\n",
              "   'patterns': ['I need to create a new account',\n",
              "    'how to open a new account',\n",
              "    'I want to create an account',\n",
              "    'can you create an account for me',\n",
              "    'how to open a new account'],\n",
              "   'responses': ['You can just easily create a new account from our web site',\n",
              "    'Just go to our web site and follow the guidelines to create a new account']},\n",
              "  {'tag': 'complaint',\n",
              "   'patterns': ['have a complaint',\n",
              "    'I want to raise a complaint',\n",
              "    'there is a complaint about a service'],\n",
              "   'responses': ['Please provide us your complaint in order to assist you',\n",
              "    'Please mention your complaint, we will reach you and sorry for any inconvenience caused']}]}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preparation:\n",
        "The second step of this task to create a chatbot with Python and Machine Learning is to prepare the data to train our chatbot. I’ll start this step by importing the necessary libraries and packages:"
      ],
      "metadata": {
        "id": "86RCE1KeuwLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "I6on-rHyu4H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will read the JSON file and process the required files:"
      ],
      "metadata": {
        "id": "Tg0ZEvxWu7hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Dataset/Project 4/intents.json') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "labels = []\n",
        "responses = []\n",
        "\n",
        "\n",
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        training_sentences.append(pattern)\n",
        "        training_labels.append(intent['tag'])\n",
        "    responses.append(intent['responses'])\n",
        "\n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])\n",
        "\n",
        "num_classes = len(labels)"
      ],
      "metadata": {
        "id": "klkVcIA2vHVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to use the label encoder method provided by the Scikit-Learn library in Python:"
      ],
      "metadata": {
        "id": "srnVlm7Pvfzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lbl_encoder = LabelEncoder()\n",
        "lbl_encoder.fit(training_labels)\n",
        "training_labels = lbl_encoder.transform(training_labels)"
      ],
      "metadata": {
        "id": "IwOaBUTMvH6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization:\n",
        "Now we need to vectorize the data using the Tokenization method to create a chatbot with Python and Machine Learning:"
      ],
      "metadata": {
        "id": "1JHl2uKjwGEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_len = 20\n",
        "oov_token = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
      ],
      "metadata": {
        "id": "MxgtFhe4wRQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a Neural Network\n",
        "Now the next and most important step in the process of building a chatbot with Python and Machine Learning is to train a neural network. Now, I will train and create a neural network to train our chatbot:"
      ],
      "metadata": {
        "id": "HG-1T6KswSpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "epochs = 10\n",
        "history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "Gpd75lUOwYen",
        "outputId": "3d255a7e-ac97-4910-992d-0839fae94a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_1           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_1           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.1121 - loss: 2.0808\n",
            "Epoch 2/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1225 - loss: 2.0791 \n",
            "Epoch 3/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1225 - loss: 2.0787 \n",
            "Epoch 4/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1225 - loss: 2.0782 \n",
            "Epoch 5/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1121 - loss: 2.0783 \n",
            "Epoch 6/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1225 - loss: 2.0775 \n",
            "Epoch 7/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1225 - loss: 2.0772\n",
            "Epoch 8/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1225 - loss: 2.0767 \n",
            "Epoch 9/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1225 - loss: 2.0763 \n",
            "Epoch 10/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1225 - loss: 2.0757 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving The Neural Network:\n",
        "We’ve trained the model, but before we go any further in the process of building a chatbot with Python and Machine Learning, let’s save the model so that we can use this neural network in the future as well:"
      ],
      "metadata": {
        "id": "fkPUwYt2wg3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to save the trained model\n",
        "model.save(\"chat_model\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "# to save the fitted tokenizer\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# to save the fitted label encoder\n",
        "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
        "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "5oYTw5wTwiTg",
        "outputId": "a1a6216a-a177-40b8-b05e-c3877afcb5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=chat_model.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c7a14ff62366>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# to save the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chat_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         )\n\u001b[0;32m--> 114\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;34m\"Invalid filepath extension for saving. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;34m\"Please add either a `.keras` extension for the native Keras \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=chat_model."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s Build a Chatbot with Python and our Trained Machine Learning Model\n",
        "Now I am going to implement a chat function to interact with a real user. When the message from the user will be received, the chatbot will compute the similarity between the sequence of the new text and the training data.\n",
        "\n",
        "Taking into account the trust scores obtained for each category, it categorizes the user’s message according to an intention with the highest trust score:"
      ],
      "metadata": {
        "id": "OA3EZ5e5wtdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import colorama\n",
        "colorama.init()\n",
        "from colorama import Fore, Style, Back\n",
        "\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "with open(\"intents.json\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "\n",
        "def chat():\n",
        "    # load trained model\n",
        "    model = keras.models.load_model('chat_model')\n",
        "\n",
        "    # load tokenizer object\n",
        "    with open('tokenizer.pickle', 'rb') as handle:\n",
        "        tokenizer = pickle.load(handle)\n",
        "\n",
        "    # load label encoder object\n",
        "    with open('label_encoder.pickle', 'rb') as enc:\n",
        "        lbl_encoder = pickle.load(enc)\n",
        "\n",
        "    # parameters\n",
        "    max_len = 20\n",
        "\n",
        "    while True:\n",
        "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
        "        inp = input()\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
        "                                             truncating='post', maxlen=max_len))\n",
        "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
        "\n",
        "        for i in data['intents']:\n",
        "            if i['tag'] == tag:\n",
        "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
        "\n",
        "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
        "\n",
        "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
        "chat()"
      ],
      "metadata": {
        "id": "t99NhQDcw9eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how we can create a chatbot with Python and Machine Learning. Hope you liked this article on how to create a Chatbot with Python and Machine Learning. Please feel free to ask your valuable questions in the comments section below."
      ],
      "metadata": {
        "id": "dvaFntSXxFFK"
      }
    }
  ]
}